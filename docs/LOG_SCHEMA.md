# ðŸ“Š SchÃ©ma des Logs d'ExpÃ©rimentation

## Vue d'ensemble

Tous les logs sont enregistrÃ©s dans `logs/experiment_data.json`. Ce fichier est **OBLIGATOIRE** pour la soumission du projet.

---

## ðŸ“‹ Structure d'une EntrÃ©e de Log

```json
{
  "id": "uuid-unique-identifier",
  "timestamp": "2025-12-26T01:26:41.177789",
  "agent": "Auditor",
  "model": "gemini-2.5-flash",
  "action": "CODE_ANALYSIS",
  "details": {
    "input_prompt": "Le prompt envoyÃ© au LLM",
    "output_response": "La rÃ©ponse du LLM"
  },
  "status": "SUCCESS"
}
```

---

## ðŸ”´ Champs Obligatoires (7 champs)

| Champ | Type | Description | Exemple |
|-------|------|-------------|---------|
| `id` | string (UUID) | Identifiant unique gÃ©nÃ©rÃ© automatiquement | `"9e82e9b0-9b43-4a78-af43-d5d5ef848a2f"` |
| `timestamp` | string (ISO 8601) | Date/heure de l'action | `"2025-12-26T01:26:41.177789"` |
| `agent` | string | Nom de l'agent qui effectue l'action | `"Auditor"`, `"Fixer"`, `"Judge"` |
| `model` | string | ModÃ¨le LLM utilisÃ© | `"gemini-2.5-flash"`, `"gpt-4"` |
| `action` | string (ActionType) | Type d'action effectuÃ©e | `"CODE_ANALYSIS"`, `"FIX"` |
| `details` | object | Dictionnaire avec les dÃ©tails | Voir section suivante |
| `status` | string | RÃ©sultat de l'action | `"SUCCESS"`, `"FAILURE"` |

---

## ðŸ“¦ Champs Obligatoires dans `details`

> âš ï¸ **CRITIQUE**: Ces champs sont **OBLIGATOIRES** pour toutes les actions sauf `STARTUP`

| Champ | Type | Description | Obligatoire |
|-------|------|-------------|-------------|
| `input_prompt` | string | Le prompt complet envoyÃ© au LLM | âœ… OUI |
| `output_response` | string | La rÃ©ponse complÃ¨te du LLM | âœ… OUI |

### Champs Optionnels RecommandÃ©s

| Champ | Type | Description | Agent concernÃ© |
|-------|------|-------------|----------------|
| `file_analyzed` | string | Fichier analysÃ© | Auditor |
| `issues_found` | int | Nombre de problÃ¨mes dÃ©tectÃ©s | Auditor |
| `file_fixed` | string | Fichier corrigÃ© | Fixer |
| `issues_fixed` | list | Liste des corrections | Fixer |
| `tests_passed` | int | Tests rÃ©ussis | Judge |
| `tests_failed` | int | Tests Ã©chouÃ©s | Judge |
| `error_message` | string | Message d'erreur | Tous |

---

## ðŸŽ­ Types d'Actions (ActionType)

| ActionType | Valeur | Description | UtilisÃ© par |
|------------|--------|-------------|-------------|
| `ANALYSIS` | `"CODE_ANALYSIS"` | Audit, lecture, recherche de bugs | Auditor |
| `GENERATION` | `"CODE_GEN"` | CrÃ©ation de nouveau code/tests/docs | Fixer |
| `DEBUG` | `"DEBUG"` | Analyse d'erreurs d'exÃ©cution | Judge |
| `FIX` | `"FIX"` | Application de correctifs | Fixer |

### Utilisation en Python

```python
from src.utils.logger import ActionType

# MÃ©thode 1: Utiliser l'Enum
action=ActionType.ANALYSIS

# MÃ©thode 2: Utiliser la string directement
action="CODE_ANALYSIS"
```

---

## ðŸ¤– Agents Valides

| Agent | RÃ´le | Actions Typiques |
|-------|------|------------------|
| `Auditor` | Analyse le code, dÃ©tecte les problÃ¨mes | `CODE_ANALYSIS` |
| `Fixer` | Corrige le code, gÃ©nÃ¨re des tests | `FIX`, `CODE_GEN` |
| `Judge` | ExÃ©cute les tests, valide les corrections | `DEBUG`, `CODE_ANALYSIS` |
| `System` | Actions systÃ¨me (dÃ©marrage, etc.) | `STARTUP` (exempt de validation) |

---

## âœ… Statuts Valides

| Status | Signification | Quand l'utiliser |
|--------|---------------|------------------|
| `SUCCESS` | Action rÃ©ussie | Le LLM a rÃ©pondu correctement, l'action s'est bien passÃ©e |
| `FAILURE` | Action Ã©chouÃ©e | Erreur LLM, parsing Ã©chouÃ©, exception |
| `INFO` | Information systÃ¨me | Logs de dÃ©marrage, Ã©vÃ©nements non-critiques |

### CritÃ¨res de DÃ©cision

```
SUCCESS si:
â”œâ”€â”€ Le LLM a rÃ©pondu sans erreur
â”œâ”€â”€ La rÃ©ponse est parseable (si JSON attendu)
â”œâ”€â”€ L'action demandÃ©e a Ã©tÃ© accomplie
â””â”€â”€ Pas d'exception Python

FAILURE si:
â”œâ”€â”€ Timeout du LLM
â”œâ”€â”€ RÃ©ponse non parseable
â”œâ”€â”€ Exception Python levÃ©e
â”œâ”€â”€ Action impossible Ã  accomplir
â””â”€â”€ Erreur de syntaxe dans le code gÃ©nÃ©rÃ©
```

---

## ðŸ“ Exemples Complets

### Exemple 1: Audit de Code (Auditor)

```json
{
  "id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "timestamp": "2025-12-26T10:30:00.000000",
  "agent": "Auditor",
  "model": "gemini-2.5-flash",
  "action": "CODE_ANALYSIS",
  "details": {
    "input_prompt": "Analyse ce code Python et identifie les problÃ¨mes:\n\ndef foo():\nreturn 42",
    "output_response": "J'ai identifiÃ© 2 problÃ¨mes:\n1. Indentation incorrecte\n2. Pas de docstring",
    "file_analyzed": "sandbox/buggy.py",
    "issues_found": 2
  },
  "status": "SUCCESS"
}
```

### Exemple 2: Correction de Code (Fixer)

```json
{
  "id": "b2c3d4e5-f6a7-8901-bcde-f23456789012",
  "timestamp": "2025-12-26T10:31:00.000000",
  "agent": "Fixer",
  "model": "gemini-2.5-flash",
  "action": "FIX",
  "details": {
    "input_prompt": "Corrige ce code selon le plan d'audit...",
    "output_response": "```python\ndef foo():\n    \"\"\"Returns 42.\"\"\"\n    return 42\n```",
    "file_fixed": "sandbox/buggy.py",
    "issues_fixed": ["indentation", "docstring"]
  },
  "status": "SUCCESS"
}
```

### Exemple 3: ExÃ©cution de Tests (Judge)

```json
{
  "id": "c3d4e5f6-a7b8-9012-cdef-345678901234",
  "timestamp": "2025-12-26T10:32:00.000000",
  "agent": "Judge",
  "model": "gemini-2.5-flash",
  "action": "DEBUG",
  "details": {
    "input_prompt": "Analyse ces rÃ©sultats de tests pytest...",
    "output_response": "Les tests passent maintenant. Action: validate",
    "tests_passed": 5,
    "tests_failed": 0,
    "test_output": "===== 5 passed in 0.02s ====="
  },
  "status": "SUCCESS"
}
```

### Exemple 4: Ã‰chec (FAILURE)

```json
{
  "id": "d4e5f6a7-b8c9-0123-defa-456789012345",
  "timestamp": "2025-12-26T10:33:00.000000",
  "agent": "Fixer",
  "model": "gemini-2.5-flash",
  "action": "FIX",
  "details": {
    "input_prompt": "Corrige ce code...",
    "output_response": "Invalid JSON response from model",
    "file_fixed": "sandbox/buggy.py",
    "error": "JSONDecodeError: Expecting value at line 1"
  },
  "status": "FAILURE"
}
```

---

## âš ï¸ Erreurs Courantes Ã  Ã‰viter

| âŒ Ne pas faire | âœ… Faire |
|-----------------|----------|
| Oublier `input_prompt` | Toujours inclure le prompt complet |
| Oublier `output_response` | Toujours inclure la rÃ©ponse du LLM |
| Utiliser un `action` invalide | Utiliser `ActionType` enum |
| Statut `SUCCESS` sur une erreur | Utiliser `FAILURE` si exception |
| Ã‰craser le fichier de logs | Append seulement (gÃ©rÃ© par logger) |

---

## ðŸ” Validation

ExÃ©cutez le validateur pour vÃ©rifier vos logs:

```bash
python -m src.utils.data_validator
```

RÃ©sultat attendu:
```
ðŸŽ‰ VERDICT: LOGS VALIDES ET COMPLETS
```

---

## ðŸ“ Fichier de Sortie

**Chemin**: `logs/experiment_data.json`

> âš ï¸ Ce fichier est dans `.gitignore`. Pour la soumission, exÃ©cutez:
> ```bash
> git add -f logs/experiment_data.json
> ```
