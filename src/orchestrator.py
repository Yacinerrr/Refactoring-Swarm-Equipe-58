"""
Updated Orchestrator - 3-Agent Collaborative System
====================================================
AUDITOR â†’ CORRECTOR â†’ TESTER (with feedback loop)
"""

from langgraph.graph import StateGraph, END
from typing import Dict, Any, TypedDict
import json

from src.refactoring_state import (
    RefactoringState,
    create_initial_state,
    check_iteration_limit,
    increment_iteration,
    mark_mission_complete
)
from src.agents.auditor_agent import run_auditor_agent
from src.agents.corrector_agent import run_corrector_agent
from src.agents.tester_agent import run_tester_agent


# ============================================================
# NÅ’UDS DU GRAPHE (3 Agents)
# ============================================================

def auditor_node(state: RefactoringState) -> RefactoringState:
    """
    AGENT 1: AUDITOR
    - Analyse code avec pylint
    - Comprend l'intent sÃ©mantique des fonctions
    - Produit plan de refactoring + comportements attendus
    """
    print("\nğŸ” [AUDITOR] Analyse sÃ©mantique du code...")
    
    try:
        result = run_auditor_agent(
            sandbox_dir=state["sandbox_dir"],
            model_used=state["model_used"]
        )
        
        # Update state with Auditor's outputs
        state["audit_complete"] = True
        state["audit_plan"] = result.get("refactoring_plan", {})
        
        # Extract expected_behaviors from result (not from refactoring_plan)
        expected_behaviors = result.get("expected_behaviors", [])
        state["expected_behaviors"] = expected_behaviors
        
        state["total_issues_found"] = result.get("issues_found", 0)
        
        print(f"âœ… [AUDITOR] Complete:")
        print(f"   - {len(expected_behaviors)} comportement(s) attendu(s) identifiÃ©(s)")
        print(f"   - {state['total_issues_found']} problÃ¨me(s) dÃ©tectÃ©(s)")
        
        # If no issues found, we can skip to testing
        if state["total_issues_found"] == 0:
            print("   â„¹ï¸ Aucun problÃ¨me - passage direct au Tester")
            state["should_continue"] = False
        
    except Exception as e:
        print(f"âŒ [AUDITOR] Erreur: {e}")
        state["error_occurred"] = True
        state["error_message"] = f"Auditor error: {str(e)}"
        state["should_continue"] = False
    
    return state


def corrector_node(state: RefactoringState) -> RefactoringState:
    """
    AGENT 2: CORRECTOR
    - ReÃ§oit le plan de l'Auditor (avec comportements attendus)
    - ReÃ§oit le feedback du Tester (si en boucle)
    - Corrige syntax ET logique
    """
    print(f"\nğŸ”§ [CORRECTOR] Correction (ItÃ©ration {state['current_iteration'] + 1})...")
    
    try:
        # Increment iteration
        state = increment_iteration(state)
        
        # Check iteration limit
        if check_iteration_limit(state):
            print(f"âš ï¸ [CORRECTOR] Limite d'itÃ©rations atteinte ({state['max_iterations']})")
            state["should_continue"] = False
            state["error_occurred"] = True
            state["error_message"] = "Max iterations reached"
            return state
        
        # Get test feedback if we're in a loop
        test_feedback = None
        if state.get("test_results") and not state.get("tests_passed"):
            test_feedback = state["test_results"]
        
        # Get expected_behaviors from state
        expected_behaviors = state.get("expected_behaviors", [])
        
        # Run corrector with ALL context
        result = run_corrector_agent(
            audit_plan=state["audit_plan"],
            expected_behaviors=expected_behaviors,
            test_feedback=test_feedback,
            sandbox_dir=state["sandbox_dir"],
            model_used=state["model_used"]
        )
        
        # Update state
        if result.get("files_modified"):
            state["files_fixed"].extend(result["files_modified"])
            state["total_issues_fixed"] += len(result.get("changes", []))
        
        print(f"âœ… [CORRECTOR] {len(result.get('files_modified', []))} fichier(s) modifiÃ©(s)")
        
    except Exception as e:
        print(f"âŒ [CORRECTOR] Erreur: {e}")
        state["error_occurred"] = True
        state["error_message"] = f"Corrector error: {str(e)}"
        state["should_continue"] = False
    
    return state


def tester_node(state: RefactoringState) -> RefactoringState:
    """
    AGENT 3: TESTER
    - ReÃ§oit les comportements attendus de l'Auditor
    - GÃ‰NÃˆRE des tests sÃ©mantiques intelligents
    - EXÃ‰CUTE pytest
    - ANALYSE les rÃ©sultats
    - Fournit feedback dÃ©taillÃ© au Corrector si Ã©chec
    """
    print("\nğŸ§ª [TESTER] GÃ©nÃ©ration et validation des tests...")
    
    try:
        # Get expected_behaviors from state
        expected_behaviors = state.get("expected_behaviors", [])
        
        result = run_tester_agent(
            expected_behaviors=expected_behaviors,
            sandbox_dir=state["sandbox_dir"],
            model_used=state["model_used"]
        )
        
        # Update state with test results
        state["test_results"] = result
        state["tests_passed"] = (result.get("test_status") == "success")
        state["failing_tests"] = result.get("failing_tests", [])
        
        # Decide next action
        if state["tests_passed"]:
            print("âœ… [TESTER] Tous les tests passent!")
            state["should_continue"] = False
            state = mark_mission_complete(state, success=True)
        else:
            print(f"âŒ [TESTER] {len(state['failing_tests'])} test(s) Ã©choue(nt)")
            
            # Check if we should continue
            if check_iteration_limit(state):
                print(f"âš ï¸ [TESTER] Limite d'itÃ©rations atteinte, arrÃªt")
                state["should_continue"] = False
                state = mark_mission_complete(state, success=False)
            else:
                print("ğŸ” [TESTER] Retour au Corrector avec feedback...")
                state["should_continue"] = True
        
    except Exception as e:
        print(f"âŒ [TESTER] Erreur: {e}")
        import traceback
        traceback.print_exc()  # Print full error for debugging
        state["error_occurred"] = True
        state["error_message"] = f"Tester error: {str(e)}"
        state["should_continue"] = False
    
    return state


# ============================================================
# FONCTIONS DE ROUTAGE
# ============================================================

def should_go_to_corrector(state: RefactoringState) -> str:
    """DÃ©cide si on passe au Corrector ou si on skip."""
    if state["error_occurred"]:
        return "end"
    
    if state["total_issues_found"] == 0:
        return "tester"  # No issues, go straight to testing
    
    return "corrector"  # Issues found, need fixing


def should_continue_loop(state: RefactoringState) -> str:
    """DÃ©cide si on continue la boucle Corrector â† Tester."""
    # If error or mission complete, stop
    if state["error_occurred"] or state["mission_complete"]:
        return "end"
    
    # If tests passed, we're done
    if state["tests_passed"]:
        return "end"
    
    # If should continue and not at limit, go back to corrector
    if state["should_continue"] and not check_iteration_limit(state):
        return "corrector"
    
    return "end"


# ============================================================
# CONSTRUCTION DU GRAPHE
# ============================================================

def build_refactoring_graph() -> StateGraph:
    """
    Construit le graphe LangGraph pour le systÃ¨me 3-agents.
    
    FLOW:
    START â†’ AUDITOR â†’ (decision) â†’ CORRECTOR â†’ TESTER â†’ (loop?) â†’ END
                           â†“
                       (no issues)
                           â†“
                        TESTER â†’ END
    """
    workflow = StateGraph(RefactoringState)
    
    # Add the 3 agent nodes
    workflow.add_node("auditor", auditor_node)
    workflow.add_node("corrector", corrector_node)
    workflow.add_node("tester", tester_node)
    
    # Set entry point
    workflow.set_entry_point("auditor")
    
    # Auditor â†’ Corrector or Tester (depending on issues found)
    workflow.add_conditional_edges(
        "auditor",
        should_go_to_corrector,
        {
            "corrector": "corrector",
            "tester": "tester",
            "end": END
        }
    )
    
    # Corrector â†’ always goes to Tester
    workflow.add_edge("corrector", "tester")
    
    # Tester â†’ either END or back to Corrector (feedback loop)
    workflow.add_conditional_edges(
        "tester",
        should_continue_loop,
        {
            "corrector": "corrector",  # Loop back with feedback
            "end": END
        }
    )
    
    return workflow.compile()


# ============================================================
# FONCTION PRINCIPALE
# ============================================================

def run_refactoring_swarm(sandbox_dir: str, max_iterations: int = 10) -> Dict[str, Any]:
    """
    Lance le systÃ¨me de refactoring Ã  3 agents.
    
    Args:
        sandbox_dir: Chemin du dossier sandbox
        max_iterations: Nombre maximum d'itÃ©rations
    
    Returns:
        dict: RÃ©sultat final avec statistiques
    """
    print("="*70)
    print("ğŸ¤– REFACTORING SWARM - 3-Agent Collaborative System")
    print("="*70)
    print(f"ğŸ“ Sandbox: {sandbox_dir}")
    print(f"ğŸ”„ Max itÃ©rations: {max_iterations}")
    print("\nğŸ¯ Workflow: AUDITOR â†’ CORRECTOR â†’ TESTER (loop)")
    
    # Create initial state
    initial_state = create_initial_state(sandbox_dir, max_iterations)
    
    # Build and run workflow
    graph = build_refactoring_graph()
    final_state = graph.invoke(initial_state)
    
    # Display summary
    print("\n" + "="*70)
    if final_state["mission_complete"] and not final_state["error_occurred"]:
        print("âœ… MISSION TERMINÃ‰E AVEC SUCCÃˆS")
    elif final_state["error_occurred"]:
        print("âŒ MISSION Ã‰CHOUÃ‰E")
        print(f"   Erreur: {final_state['error_message']}")
    else:
        print("âš ï¸ MISSION INCOMPLÃˆTE")
    
    print("="*70)
    print(f"ğŸ“Š Statistiques:")
    print(f"   - ProblÃ¨mes dÃ©tectÃ©s: {final_state['total_issues_found']}")
    print(f"   - ProblÃ¨mes corrigÃ©s: {final_state['total_issues_fixed']}")
    print(f"   - ItÃ©rations utilisÃ©es: {final_state['current_iteration']}/{max_iterations}")
    print(f"   - Tests rÃ©ussis: {'âœ… Oui' if final_state['tests_passed'] else 'âŒ Non'}")
    print(f"   - Comportements validÃ©s: {len(final_state.get('expected_behaviors', []))}")
    print("="*70)
    
    return {
        "success": final_state["mission_complete"] and not final_state["error_occurred"],
        "iterations_used": final_state["current_iteration"],
        "issues_found": final_state["total_issues_found"],
        "issues_fixed": final_state["total_issues_fixed"],
        "tests_passed": final_state["tests_passed"],
        "behaviors_validated": len(final_state.get("expected_behaviors", [])),
        "error": final_state.get("error_message")
    }