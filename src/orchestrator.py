"""
LangGraph Orchestrator - Moteur de workflow pour le systÃ¨me multi-agents
=========================================================================
Ce module orchestre la collaboration entre Auditor, Fixer et Judge
en utilisant LangGraph pour gÃ©rer le flux d'exÃ©cution.
"""

from langgraph.graph import StateGraph, END
from typing import Dict, Any
import json

from src.refactoring_state import (
    RefactoringState,
    create_initial_state,
    check_iteration_limit,
    increment_iteration,
    mark_mission_complete
)
from src.agents.auditor_agent import run_auditor_agent
from src.agents.corrector_agent import run_corrector_agent
from src.agents.tester_agent import run_tester_agent


# ============================================================
# NÅ’UDS DU GRAPHE (Agent Functions)
# ============================================================

def auditor_node(state: RefactoringState) -> RefactoringState:
    """
    NÅ“ud Auditor: Analyse le code et produit un plan de refactoring.
    
    Args:
        state: Ã‰tat actuel du systÃ¨me
    
    Returns:
        RefactoringState: Ã‰tat mis Ã  jour avec le plan d'audit
    """
    print("\nğŸ” [AUDITOR] Analyse du code en cours...")
    
    try:
        # Appeler l'agent Auditor
        result = run_auditor_agent(
            sandbox_dir=state["sandbox_dir"],
            model_used=state["model_used"]
        )
        
        # Mettre Ã  jour l'Ã©tat
        state["audit_complete"] = True
        state["audit_plan"] = result.get("refactoring_plan", {})
        state["total_issues_found"] = result.get("issues_found", 0)
        
        # Extraire la liste des fichiers Ã  corriger
        files_to_fix = []
        if "files_to_fix" in state["audit_plan"]:
            for file_info in state["audit_plan"]["files_to_fix"]:
                files_to_fix.append(file_info["file"])
        
        state["files_to_fix"] = files_to_fix
        
        print(f"âœ… [AUDITOR] {len(files_to_fix)} fichier(s) Ã  corriger")
        print(f"   Total problÃ¨mes: {state['total_issues_found']}")
        
        # Si aucun problÃ¨me trouvÃ©, on peut terminer
        if state["total_issues_found"] == 0:
            print("âœ¨ [AUDITOR] Aucun problÃ¨me dÃ©tectÃ©!")
            state["should_continue"] = False
            state["tests_passed"] = True
        
    except Exception as e:
        print(f"âŒ [AUDITOR] Erreur: {e}")
        state["error_occurred"] = True
        state["error_message"] = f"Auditor error: {str(e)}"
        state["should_continue"] = False
    
    return state


def fixer_node(state: RefactoringState) -> RefactoringState:
    """
    NÅ“ud Fixer: Applique les corrections selon le plan d'audit.
    
    Args:
        state: Ã‰tat actuel du systÃ¨me
    
    Returns:
        RefactoringState: Ã‰tat mis Ã  jour avec les corrections appliquÃ©es
    """
    print(f"\nğŸ”§ [FIXER] Correction des fichiers (ItÃ©ration {state['current_iteration'] + 1})...")
    
    try:
        # IncrÃ©menter le compteur d'itÃ©rations
        state = increment_iteration(state)
        
        # VÃ©rifier la limite d'itÃ©rations
        if check_iteration_limit(state):
            print(f"âš ï¸ [FIXER] Limite d'itÃ©rations atteinte ({state['max_iterations']})")
            state["should_continue"] = False
            state["error_occurred"] = True
            state["error_message"] = "Max iterations reached"
            return state
        
        # RÃ©cupÃ©rer le plan d'audit
        audit_plan_json = json.dumps(state["audit_plan"], indent=2, ensure_ascii=False)
        
        # Pour chaque fichier Ã  corriger
        files_fixed_this_iteration = 0
        for file_info in state["audit_plan"].get("files_to_fix", []):
            file_path = file_info["file"]
            
            # Si on a des rÃ©sultats de tests qui ont Ã©chouÃ©, les inclure
            test_feedback = ""
            if state["failing_tests"]:
                test_feedback = "\n\n=== FEEDBACK DES TESTS ===\n"
                test_feedback += json.dumps(state["failing_tests"], indent=2, ensure_ascii=False)
            
            print(f"   ğŸ“ Correction de: {file_path}")
            
            # Appeler l'agent Fixer
            result = run_corrector_agent(
                audit_plan=audit_plan_json + test_feedback,
                target_file=file_path,
                sandbox_dir=state["sandbox_dir"],
                model_used=state["model_used"]
            )
            
            if result.get("status") == "modified":
                files_fixed_this_iteration += 1
                state["total_issues_fixed"] += len(result.get("changes", []))
        
        print(f"âœ… [FIXER] {files_fixed_this_iteration} fichier(s) modifiÃ©(s)")
        
    except Exception as e:
        print(f"âŒ [FIXER] Erreur: {e}")
        state["error_occurred"] = True
        state["error_message"] = f"Fixer error: {str(e)}"
        state["should_continue"] = False
    
    return state


def judge_node(state: RefactoringState) -> RefactoringState:
    """
    NÅ“ud Judge: ExÃ©cute les tests et dÃ©cide si on continue ou pas.
    
    Args:
        state: Ã‰tat actuel du systÃ¨me
    
    Returns:
        RefactoringState: Ã‰tat mis Ã  jour avec les rÃ©sultats des tests
    """
    print("\nâš–ï¸ [JUDGE] ExÃ©cution des tests...")
    
    try:
        # Appeler l'agent Tester
        result = run_tester_agent(
            target_dir=state["sandbox_dir"],
            model_used=state["model_used"]
        )
        
        # Mettre Ã  jour l'Ã©tat
        state["test_results"] = result
        state["tests_passed"] = (result.get("test_status") == "success")
        state["failing_tests"] = result.get("failing_tests", [])
        
        # DÃ©cider si on continue
        if state["tests_passed"]:
            print("âœ… [JUDGE] Tous les tests passent!")
            state["should_continue"] = False
            state = mark_mission_complete(state, success=True)
        else:
            print(f"âŒ [JUDGE] {len(state['failing_tests'])} test(s) Ã©choue(nt)")
            
            # VÃ©rifier si on doit continuer
            if check_iteration_limit(state):
                print(f"âš ï¸ [JUDGE] Limite d'itÃ©rations atteinte, arrÃªt.")
                state["should_continue"] = False
                state = mark_mission_complete(state, success=False)
            else:
                print("ğŸ” [JUDGE] Retour au Fixer pour corrections...")
                state["should_continue"] = True
        
    except Exception as e:
        print(f"âŒ [JUDGE] Erreur: {e}")
        state["error_occurred"] = True
        state["error_message"] = f"Judge error: {str(e)}"
        state["should_continue"] = False
    
    return state


# ============================================================
# FONCTIONS DE ROUTAGE (Conditional Edges)
# ============================================================

def should_continue_fixing(state: RefactoringState) -> str:
    """
    DÃ©cide si on doit continuer la boucle Fixer â†’ Judge.
    
    Args:
        state: Ã‰tat actuel
    
    Returns:
        str: "continue" pour retourner au Fixer, "end" pour terminer
    """
    # Si erreur ou mission terminÃ©e, on arrÃªte
    if state["error_occurred"] or state["mission_complete"]:
        return "end"
    
    # Si les tests passent, on termine
    if state["tests_passed"]:
        return "end"
    
    # Si on doit continuer et qu'on n'a pas atteint la limite
    if state["should_continue"] and not check_iteration_limit(state):
        return "continue"
    
    return "end"


def after_audit_routing(state: RefactoringState) -> str:
    """
    DÃ©cide quoi faire aprÃ¨s l'audit.
    
    Args:
        state: Ã‰tat actuel
    
    Returns:
        str: "fix" pour aller au Fixer, "end" si rien Ã  faire
    """
    # Si erreur, on arrÃªte
    if state["error_occurred"]:
        return "end"
    
    # Si aucun problÃ¨me trouvÃ©, on peut sauter au Judge pour vÃ©rifier
    if state["total_issues_found"] == 0:
        return "judge"
    
    # Sinon, on va au Fixer
    return "fix"


# ============================================================
# CONSTRUCTION DU GRAPHE LANGGRAPH
# ============================================================

def build_refactoring_graph() -> StateGraph:
    """
    Construit le graphe LangGraph pour le systÃ¨me de refactoring.
    
    Architecture du graphe:
    
        START
          â†“
       AUDITOR â”€â”€â”€â”€â”€â†’ (si aucun problÃ¨me) â†’ JUDGE â†’ END
          â†“
       FIXER
          â†“
       JUDGE â”€â”€â†’ (si tests OK) â†’ END
          â†“
          â””â”€â”€â†’ (si tests KO) â†’ FIXER (loop)
    
    Returns:
        StateGraph: Le graphe compilÃ©
    """
    # CrÃ©er le graphe
    workflow = StateGraph(RefactoringState)
    
    # Ajouter les nÅ“uds (agents)
    workflow.add_node("auditor", auditor_node)
    workflow.add_node("fixer", fixer_node)
    workflow.add_node("judge", judge_node)
    
    # DÃ©finir le point d'entrÃ©e
    workflow.set_entry_point("auditor")
    
    # Ajouter les arÃªtes conditionnelles
    workflow.add_conditional_edges(
        "auditor",
        after_audit_routing,
        {
            "fix": "fixer",
            "judge": "judge",
            "end": END
        }
    )
    
    # Du Fixer au Judge (toujours)
    workflow.add_edge("fixer", "judge")
    
    # Du Judge, soit on termine, soit on retourne au Fixer
    workflow.add_conditional_edges(
        "judge",
        should_continue_fixing,
        {
            "continue": "fixer",
            "end": END
        }
    )
    
    # Compiler le graphe
    return workflow.compile()


# ============================================================
# FONCTION PRINCIPALE D'EXÃ‰CUTION
# ============================================================

def run_refactoring_swarm(sandbox_dir: str, max_iterations: int = 10) -> Dict[str, Any]:
    """
    Lance le systÃ¨me de refactoring multi-agents sur un sandbox.
    
    Args:
        sandbox_dir: Chemin du dossier sandbox Ã  traiter
        max_iterations: Nombre maximum d'itÃ©rations
    
    Returns:
        dict: RÃ©sultat final avec statistiques
    """
    print("="*60)
    print("ğŸ¯ DÃ‰MARRAGE DU REFACTORING SWARM")
    print("="*60)
    print(f"ğŸ“ Sandbox: {sandbox_dir}")
    print(f"ğŸ”„ Max itÃ©rations: {max_iterations}")
    
    # CrÃ©er l'Ã©tat initial
    initial_state = create_initial_state(sandbox_dir, max_iterations)
    
    # Construire et exÃ©cuter le graphe
    graph = build_refactoring_graph()
    
    # ExÃ©cuter le workflow
    final_state = graph.invoke(initial_state)
    
    # Afficher le rÃ©sumÃ©
    print("\n" + "="*60)
    if final_state["mission_complete"] and not final_state["error_occurred"]:
        print("âœ… MISSION TERMINÃ‰E AVEC SUCCÃˆS")
    elif final_state["error_occurred"]:
        print("âŒ MISSION Ã‰CHOUÃ‰E")
        print(f"   Erreur: {final_state['error_message']}")
    else:
        print("âš ï¸ MISSION INCOMPLÃˆTE")
    
    print("="*60)
    print(f"ğŸ“Š Statistiques:")
    print(f"   - ProblÃ¨mes dÃ©tectÃ©s: {final_state['total_issues_found']}")
    print(f"   - ProblÃ¨mes corrigÃ©s: {final_state['total_issues_fixed']}")
    print(f"   - ItÃ©rations utilisÃ©es: {final_state['current_iteration']}/{max_iterations}")
    print(f"   - Tests rÃ©ussis: {'âœ… Oui' if final_state['tests_passed'] else 'âŒ Non'}")
    print("="*60)
    
    return {
        "success": final_state["mission_complete"] and not final_state["error_occurred"],
        "iterations_used": final_state["current_iteration"],
        "issues_found": final_state["total_issues_found"],
        "issues_fixed": final_state["total_issues_fixed"],
        "tests_passed": final_state["tests_passed"],
        "error": final_state.get("error_message")
    }